{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework - Exercise 1\n",
        "Do the word count on `sample_data/README.md` with DataFrame API (don't use RDD API). Sort the result by descending count and make sure that empty words are not included. Hint: you can use `read.text`, `split`, `explode`, `lower`, `filter`, `select`,  `groupBy`, `count`, `orderBy` (some need to be imported from `pyspark.sql.functions`). Details can be found in the [documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)."
      ],
      "metadata": {
        "id": "cIrL-Ghny_CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PySpark installation and imports\n",
        "\n",
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet\n",
        "!apt install openjdk-8-jdk-headless &> /dev/null\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, split, lower, col, count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4rgTq-azER_",
        "outputId": "a46aee95-297d-4b4d-8373-f8b4c6e4233c",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m864.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"WordCount\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.read.text(\"sample_data/README.md\")\n",
        "\n",
        "# Split the lines into words and explode them, then remove empty words\n",
        "words_df = df.select(explode(split(lower(col(\"value\")), \"\\s+\")).alias(\"word\"))\n",
        "words_df = words_df.filter(words_df.word != '')\n",
        "\n",
        "# Group by word and count, then sort in descending order\n",
        "word_counts = words_df.groupBy(\"word\").agg(count(\"*\").alias(\"count\"))\n",
        "word_counts = word_counts.orderBy(col(\"count\").desc())\n",
        "\n",
        "word_counts.show(50)\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7e4Iw4PzY7i",
        "outputId": "f10d1cbb-8449-4b20-8f9c-c0be91637d5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|                word|count|\n",
            "+--------------------+-----+\n",
            "|                  is|    4|\n",
            "|                   *|    3|\n",
            "|                 the|    3|\n",
            "|                   a|    3|\n",
            "|                copy|    2|\n",
            "|                 was|    2|\n",
            "|                  in|    2|\n",
            "|                 at:|    2|\n",
            "|                  of|    2|\n",
            "|           described|    2|\n",
            "|              sample|    2|\n",
            "|                 few|    1|\n",
            "|       `mnist_*.csv`|    1|\n",
            "|            2682899.|    1|\n",
            "|                  us|    1|\n",
            "|         statistical|    1|\n",
            "|          originally|    1|\n",
            "|                  by|    1|\n",
            "|                 you|    1|\n",
            "|                more|    1|\n",
            "|             'graphs|    1|\n",
            "|quartet](https://...|    1|\n",
            "|              [mnist|    1|\n",
            "|            contains|    1|\n",
            "|            includes|    1|\n",
            "|            american|    1|\n",
            "|     `anscombe.json`|    1|\n",
            "|                  27|    1|\n",
            "|             housing|    1|\n",
            "|library](https://...|    1|\n",
            "|       statistician.|    1|\n",
            "|            prepared|    1|\n",
            "|          analysis'.|    1|\n",
            "|database](https:/...|    1|\n",
            "|                data|    1|\n",
            "|                  it|    1|\n",
            "|                 our|    1|\n",
            "|      [vega_datasets|    1|\n",
            "|                from|    1|\n",
            "|            datasets|    1|\n",
            "|            started.|    1|\n",
            "|                 and|    1|\n",
            "|               small|    1|\n",
            "|           anscombe,|    1|\n",
            "|          california|    1|\n",
            "|                  j.|    1|\n",
            "|`california_housi...|    1|\n",
            "|             census;|    1|\n",
            "|                 get|    1|\n",
            "|               jstor|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}